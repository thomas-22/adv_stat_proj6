---
title: "Hunting Effect on Individual Deer Stress Level"
subtitle: "P15.2 Fortgeschrittenes Praxisprojekt"
author: "Nikolai German, Thomas Witzani, Ziqi Xu, Zhengchen Yuan, Baisu Zhou"
lang: en
format:
  pdf:
    documentclass: scrreprt
    number-sections: true
    crossref:
      chapters: true
    bibliography: references.bib
    classoption: [twocolumn, open=any]
    lof: false
    lot: false
    header-includes: |
      \counterwithout{figure}{chapter}
      \counterwithout{table}{chapter}
      \makeatletter
      \renewcommand\chapter{\@startsection{chapter}{0}{\z@}%
        {-3.5ex \@plus -1ex \@minus -.2ex}%
        {2.3ex \@plus.2ex}%
        {\normalfont\Large\bfseries}}
      \makeatother
    toc: true
    geometry:
      - top=20mm
      - left=15mm
      - right=15mm
      - bottom=20mm
      - heightrounded
    mainfont: Arial
    colorlinks: true
---

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

<!-- The experience of hunting events causes stress in red deer, resulting in elevated faecal cortisol metabolites (FCMs). Modelling FCM levels on the spatial and temporal distance of a given deer to hunting events did not show significant effects due to uncertainty within the data. However, we were able to show some relationship between *sampling delay* and FCM levels. -->

Hunting activity has an impact on animal populations through removal of individuals. Moreover, it may have a non-lethal effect of inducing stress. In this project, we analyze the short-term stress response of red deer in the Bavarian Forest National Park to hunting events. The stress level of a deer was measured by the concentration of faecal cortisl metabolites (FCMs) in faecal samples. Combining spatiotemporal information about the faecal samples, the deer which produced them, and the hunting events occurred in the time period of sample collection, we aim to address how the FCM level in a deer's faecal matter is associated with the temporal and spatial distance to a hunting event that could have affected the deer.

# Introduction

## Background

Apart from the change in populations size, the effects of hunting on wildlife have so far been studied mainly on the basis of behavioral changes. This project aims to investigate the physiological stress response in red deer using a non-invasive method, the measurement of FCMs.

## Data Generating Process

The data for the project origins in the *Bavarian Forest National Park*. Its location is highlighted in green in @fig-park_location. Within and on the borders of this area, red deer roam freely. Some of these deer have been collared with a GPS-device, which helps to track the movement. At some time, a *hunting event* happens and the deer experiences some amount of stress. Later, the deer defecates ("*defecation event*"). Subsequently, researchers visit the defecation location and collect a *faecal sample*.

![Location of Bavarian Forest National Park](Figures/sp_park_location.png){#fig-park_location}

Stress is expected to be higher in proximity[^1] to hunting events. With higher stress, FCM values are expected to be higher. @Huber2003 showed (@fig-fcm) that the FCM levels peak between 16 and 19 hours after a stress event (called "challenge"). Additionally we expect, that FCM levels are lower, the more time passes between defecation and sampling.

[^1]: this includes temporal and spatial proximity

![FCM levels over time](Figures/Huber_et_al_FCM_levels.png){#fig-fcm}

## Research Question

Therefore our research question is two-fold:

-   assess the effect of temporal and spatial distance on FCM level
-   assess if the time between defecation event and sample collection affect the FCM levels

# Data Analysis

We were provided with four distinct datasets.  In the following subchapters we are going to describe the main features of each data set and address any anomalies.

## Reproduction Data
The reproduction data has not been used in our analysis and modelling approach, for the reasons see @sec-feature_selection.

## Hunting Events

The dataset contains the location and time of 697 individual hunting events, spanning from 2020 to 2022. There are three main challenges:

i)  Just 519 of these 697 events have a complete timestamp, consisting of date and time of day. The remainder of 178 events only reported the date of the event.
ii) The events are not represented as a period of time, but as a as a single moment in time. Additionally, as shown in @fig-hunts_dates, there appears to be seasonality in the occurrence of hunts.
iii) Similiarly to ii), the events are only associated with a single spatial point. The locations of the events with complete timestamps are illustrated in @fig-hunt_locations.

![Hunts - Daily Count](Figures/hunts_dates.png){#fig-hunts_dates}

![Hunts - Locations](Figures/sp_hunts.png){#fig-hunt_locations}

## Movement Data

There are 40 collared deers which movements have been tracked completely or partially between February 2020 and February 2023. Some collars stopped working before the end-date, some deers got collared within the timespan of interest. The location of each individual deer is tracked on an hourly basis. The movement of four randomly selected deer is visualised in @fig-deers_locations. During the winter months, the deers roam in one of four enclosures within the national park.

![Deers - Locations of four Deer](Figures/sp_movement_4.png){#fig-deers_locations}

## Faecal Sample Data

The faecal sample dataset contains information on 809 faecal samples. Most importantly, the FCM-level (in nanograms per gram \[ng/g\]), the location of the sample, as shown in @fig-samples_locations, the associated collared deer, the approximate time of defecation and the time of sampling. The samples were taken at irregular intervals, but with obvious seasonality (see @fig-samples_daily_count) from 2020 to 2022.

![Samples - Daily Count](Figures/samples_daily_count.png){#fig-samples_daily_count}

![Samples - Locations](Figures/sp_samples.png){#fig-samples_locations}

# Data Preprocessing

The datasets undergo preprocessing steps to facilitate analysis and modelling:

-   Convertion of Timestamps and Coordinates to a uniform format
-   Removal of entries with missing values (especially timestamps), zeros, or highly implausible data

Each FCM sample gets associated with all hunting events occurring before the sample was produced. The resulting dataset containes samples linked to all prior hunting events, creating multiple pairings per sample.

## Filtering {#sec-filtering}

A hunting event and a deer are separated by both space and time. Therefore we define the essential covariates to be:

i)  *Time Difference* between the hunting event and the subsequent defecation
ii) *Spatial Distance* between a deer and the hunting event at the exact time of the event

Additionally we identify other covariates:

iii) Time Difference between defecation and sampling (*Sample Delay*)
iv) day of year \[1-365\] (*Defecation Day*)
v)  Number of hunts a deer experiences before defecation (*Number of Other Hunts*)

As each sample is associated with one or more hunting event, the main challenge is to identify the most relevant hunting event. We propose three different criterions to identify which hunting event is the most relevant one:

1.  *Closest in time*: Choosing the hunting event, which happened closest to 19 hours prior to the defecation event.
  <!-- \begin{equation*}
    \operatorname*{argmin}_{t_\text{Hunt}}\, |(t_\text{Defecation} - 19h) - t_\text{Hunt}|
  \end{equation*} -->
  This takes the findings of @Huber2003 into account, that cortisol metabolite concentrations peak around 19 hours post-stress event (see @fig-fcm).

2.  *Nearest*: Choosing the observation with the shortest spatial distance between the hunting event and the deer’s interpolated position at the time of the hunting event.

3.  *Highest score*: Introducing a scoring function to consider both spatial and temporal distance. We designed a score proportional to the inverse square of the distance and a "spike" function based on Time Difference (see @fig-score). The inverse square component is inspired by the inverse square law for sound intensity, spike function was inspired by the general dynamics of stress responses, incorporating insights from @Huber2003, and @Pinero2025. The observation with the highest score was selected.

![Score Function](Figures/Timediff_Function_impact_curve.png){#fig-score}

$$ 
S(d, t) \propto \frac{1}{d^2} \cdot \begin{cases}
f_\textbf{t}(t), \hspace{.1cm} \textbf{t} \sim \mathcal{N}(\mu, \sigma^2) &|t \leq \mu \\
f_\textbf{t}(t), \hspace{.1cm} \textbf{t} \sim \mathcal{Laplace}(\mu, b) &|t > \mu
\end{cases}
$$

Where $d$ is the spatial distance, $t$ the Time Difference between hunting and defecation event, while $\mu = 19$, once again incoporates @Huber2003 findings. $\sigma = 2$ and $b = 2.5$ are shape paramters.

Having identified the most relevant hunting event, covariate i) can be calculated easily as the Time Difference of the hunting event and the defecation event. To obtain covariate ii) we have to take in account, that the movement data is recorded in 1-hour intervals, while the hunting events occur at arbitrary times. Therefore we need to approximate the exact deer positions at hunting event times. We interpolate deer positions at the timestamp of each hunting event, assuming constant velocity and linear movement. Features iii) and iv) are again easy to obtain. For covariate v), we need to define a cutoff point in time and space, to identify which other hunting events could have affected a deer as well (see @tbl-thresholds).

```{r include=TRUE, echo=FALSE}
#| label: tbl-thresholds
#| tbl-cap: "Thresholds"
data <- readRDS("Data/intermediate/param_grid.RDS")

data$filter_criterion[data$filter_criterion == "last"] <- "closest in time"
data$filter_criterion[data$filter_criterion == "score"] <- "highest score"
data <- dplyr::select(data, filter_criterion, gut_retention_time_upper, distance_threshold)

tab <- knitr::kable(data, 
             format = "latex", 
             align = c("l", "r", "r"), 
             col.names = c("Dataset",
                          "Temporal [h]",
                          "Spatial [km]"
                          ))

kableExtra::kable_styling(tab, font_size = 10)
```

## Uncertainties

A major challenge in our analysis is the large uncertainty in data which propogates through the pre-processing steps into our models.

First, the uncertainty about spatial distances between deer and hunting events is large. While the movement of deer was tracked at hourly intervals, hunting events occurred irregularly. In our interpolation-based approximation of a deer's location at the time of hunting event, the approximation error is unknown.

Second, we have very limited information for addressing the short-term stress response of the deer. On the one hand, the available data contain only 500 hunting events with complete time and location information scattered across a 30km $\times$ 30km area in the span of two years. The observed hunting events only populate the space-time scarcely. On the other hand, we observe in @fig-deers_locations that the deer tended to roam around within a small area. As a result, each deer is likely to have only encountered very few hunting events at small spatial and temporal distances.

Third, there could be a large number of confounders for which we possess no information. Based on GPS coordinates, we can compute Euclidean distances between deer and hunting events. However, we cannot account for terrain and vegetation which could affect the propagation of sound and therefore contaminate the potential effect of hunting events. Furthermore, there could be unobserved stress stimuli, such as weather conditions, predators, and human activities other than hunting.

Fourth, we assumed that each hunting event was actually a sound event (i.e. a shot was fired). Therefore, we weighted the value of our score function by the inverse square distance.

# Model Selection

To address how the FCM level depends on Time Difference and spatial distance, we follow a statistical approach for interpretability and a machine learning approach for exploration. In this section, we present details on model specification. Both approaches use all the datasets shown in @tbl-datasets.

```{r include=TRUE, echo=FALSE}
#| label: tbl-datasets 
#| tbl-cap: "Datasets" 
data <- readRDS("Data/processed/Datasets.RDS")
data$filter_criterion[data$filter_criterion == "last"] <- "closest in time"
data <- dplyr::select(data, filter_criterion, unique_deers, obs)
tab <- knitr::kable(data, 
                    format = "latex", 
                    align = c("r", "r", "r"),
                    col.names = c("DataSet",
                                  "Deer",
                                  "Observations"))
kableExtra::kable_styling(tab, font_size = 10)
```

## Statistical modeling approach {#sec-stat_model}

For each dataset shown in @tbl-datasets, we consider the five covariates introduced in @sec-filtering.

The *Time Difference* and *spatial distance* are of main interest for our first research question. The effect of *sample delay* is the subject of our second research question. We consider the *day of defecation* as a potential confounder, as the deer's stress level exhibits seasonal patterns [@Vilela2020]. The *number of other relevant hunting events* reflects the intensity of recent hunting activity. In time periods of frequent hunting events, a deer might have a generally higher stress level, or adaptation might occur which dampens the stress response towards new hunting events.

We propose a generalized additive mixed model (GAMM) to account for potentially non-linear effects of covariates and potential individual differences between the observed deer. We use the R package `mgcv` [@mgcv] to fit the models. The covariates Time Difference, Distance, Sample Delay, and Defecation Day are encoded by penalized cubic regression splines. We do not use a cyclical spline for Defecation Day, because faecal samples were not collected during winter and therefore Defecation Day is not a cyclical variable. The Number of Other Relevant Hunting Events is adopted as a linear effect. We further introduce a random intercept for each deer.

For the distributional assumption, we use the Gamma family with a log link. Since the FCM level is non-negative, we expect the Gamma assumption to more appropriate than Gaussian. A full specification of our GAMM model is as follows. Let $i = 1,\dots,N$ be the indices of the deer and $j = 1,\dots,n_i$ be the indices of faecal samples for each deer \begin{align*}
\textup{FCM}_{ij} &\overset{\mathrm{iid}}{\sim} \mathcal{Ga}\left( \nu, \frac{\nu}{\mu_{ij}} \right) \quad\text{for}\; j = 1,\dots,n_i, \\
\mu_{ij} &= \mathbb{E}(\textup{FCM}_{ij}) = \exp(\eta_{ij}), \\
\eta_{ij} &= \beta_0 \\
&+ \beta_1 \textup{Number of Other Relevant Hunting Events}_{ij} \\
&+ f_1(\textup{Time Difference}_{ij}) + f_2(\textup{Distance}_{ij}) \\
&+ f_3(\textup{Sample Delay}_{ij}) + f_4(\textup{Defecation Day}_{ij}) \\
&+ \gamma_{i}, \\
\gamma_i &\overset{\mathrm{iid}}{\sim} \mathcal{N}(0, \sigma_\gamma^2),
\end{align*} where $f_1, f_2, f_3, f_4$ are penalized cubic regression splines, $\sigma_\gamma^2 > 0$, and $\nu > 0$.

Our model has two major limitations. First, it does not account for potential interactions between the covariates. Second, the random intercept term can only capture different base stress levels, but not differences in stress response. However, given the limited data, one must trade off between model complexity and stability in estimation. In fact, our current model already exhibits instability with respect to estimation procedures, which we discuss in @sec-results.

## Machine learning approach

@Chen2016 introduced XGBoost as a machine learning algorithm that improves prediction accuracy by building an ensemble of decision trees sequentially. Each new tree corrects the errors made by previous trees. XGBoost minimizes a loss function using gradient boosting (hence the name) by iteratively adding trees that best reduce the residual errors. Simultaneously, complexity gets penalized through regularization to prevent overfitting. A major feature of XGBoost is that it doesn't require specifying a parametric relationship between target and explanatory variables.

We propose a xgboost model using the R package `xgboost`, choosing *spatial distance* and *Time Difference* as covariates. To find the best fitting model for each dataset (see @tbl-datasets), we tune hyperparamters of the proposed xgboost model. We choose to tune the following paramters, using randomized grid search [@Bergstra2012]:

-   *maximum depth*:  Controls the maximum depth of each decision tree, determining how complex each tree can become.
-   $\eta$:  The learning rate, controls how much each new tree contributes to the ensemble, affecting how quickly or cautiously the model learns.
-   $\gamma$:  The minimum loss reduction required to make a split, acting as a regularization parameter that prevents creating splits that don't significantly improve the model.
-   *subsample*:  Specifies the fraction of training data used to build each tree, introducing randomness to prevent overfitting.
-   *features by tree*:  Determines the fraction of features (columns) randomly sampled for each tree, increasing diversity among trees.
-   *minimum weight of child*:  Minimum sum of instance weight needed in a child node, helping control the complexity of the model by preventing overly specific partitions.

# Model Evaluation {#sec-results}

## GAMMs

We fitted and evaluated GAMM models across the three datasets, using REML and GCV as parameter estimation methods. We observed high instability with respect to the choice of dataset and estimation method.

<!-- ## Main Findings

### Smooth Effect Analysis -->

::: {#fig-gamm-reml layout-ncol=1}

![Closest in time.](Figures/Models/last_REML_diagnostic_custom.png)

![Nearest.](Figures/Models/nearest_REML_diagnostic_custom.png)

![Highest score.](Figures/Models/score_REML_diagnostic_custom.png)

Adjusted predictions for the FCM level on the three datasets. The GAMM is fitted with the REML method. Each plot shows the predicted values of the FCM level in dependence of one covariate. The other covariants are held constant at the mean. The grey area shows the approximate confidence band (mean $\pm$ 1.96 standard error).
:::

In models estimated with the REML method, the smooth effects are penalized to almost linear, as shown in @fig-gamm-reml. While the fitted curves have a similar tendency across the datasets, the standard error in estimation is generally high. Given such high uncertainty, no interpretation of the estimates is reliable. The GCV method yields more wiggly smooth effect estimates, which are visualized in @fig-gamm-gcv, but high uncertainty persists. For the other covariates, we also observe high uncertainty and therefore avoid making any unreliable statement.

On the "highest score" dataset which contains more observations than the other two datasets, both estimation methods agree on a negative non-linear effect of Sample Delay. This is in accordance with our prior knowledge that the FCM level in the faecal sample decays after defecation [@Huber2003].

Similar to the smooth and linear effects, estimation of the deer-specific random intercepts exhibits high instability. In particular, the estimated random intercepts differ in order of magnitude across different dataset (see @fig-ri).


<!-- -   Using REML, the smooth effect curves remained relatively stable, showing a consistent pattern.
-   Using GCV, the smooth effect curves exhibited strong fluctuations.
-   Across all datasets, there was high uncertainty (large standard errors) in estimated effects, particularly for Time Difference and distance.
-   A consistent sample delay effect was observed with REML: larger sample delay led to lower FCM levels, as expected.
-   Instability across estimation methods: GCV tended to produce more wiggly smooth effects compared to REML.
-   The estimation of random intercepts was sensitive to the choice of dataset. -->

<!-- ## Key Notes and Reflections

### Model Performance Concerns

The overall performance of the GAMM model, both in terms of fitting and evaluation, was unsatisfactory. Key concerns include:

-   The fluctuation of smooth effects and instability in parameter estimation indicate substantial risks in model reliability.
-   These issues may stem from factors such as limited data availability, instability in data preprocessing strategies, or other underlying methodological constraints. -->

## XGBoost

<!-- TO DO -->

After comparing the models with those trained on randomized labels, we concluded that there is some relationship between the covariates and the response, as our models slightly outperformed those trained on randomized labels. However, this relationship was very weak and not obvious or intuitive. After reviewing the hyperparameters we concluded that this was likely not noise. Although the predictive power of the XGBoost models was better than that of all other models, it was still not particularly good.

![Predictions of XGBoost models on the three datasets. The points are all observations within each dataset.](Figures/Models/xgboost_combined.png)

```{r include=TRUE, echo=FALSE}
#| label: tbl-rmse 
#| tbl-cap: "Comparison of RMSE between GAMMs and XGBoost models. The RMSE score is computed on all observations in each dataset." 
data <- readRDS("Data/processed/ComparisonRMSE.RDS")
data$rmse <- round(data$rmse, 2)
tab <- knitr::kable(data, 
                    format = "latex", 
                    align = c("r", "r", "r"),
                    col.names = c("DataSet",
                                  "Model",
                                  "RMSE"))
kableExtra::kable_styling(tab, font_size = 10)
```

# Conclusion & Outlook {#sec-outlook}

Due to the high level of uncertainty in the data, we were not able to show an effect of spatial and temporal proximity to a hunting event on the FCM levels. However, we were able to show to a certain extent that the FCM level decreases with increasing sample delay.

We believe that a more rigorous recording of hunting events (i.e. timespans instead of single moments, enforcing complete timestamps) and an overall larger amount of data could lead to less uncertainty and thus a clearer result.

\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}

We would like to express our deepest gratitude to *Dr. Nicolas Ferry* for providing us with the opportunity to work on this project.

*Daniel Schlichting*'s mentorship throughout the project was invaluable. We thank him for his guidance and patience.

\chapter*{References}
\addcontentsline{toc}{chapter}{References}

::: {#refs}
:::

\onecolumn
# Appendix

## Reproduction data {#sec-feature_selection}

<!-- descriptive analysis ... -->

As the reproductive data only contain information on a subset of the deer, we were faced with the decision of how to label the rest of the deer ("pregnant"/"not pregnant"/NA). We are convinced that imputing this information would introduce a huge bias. For this reason, we deliberately chose not to include pregnancy data in our model. However, we are strongly in favour of including additional characteristics that could explain a shift in baseline stress levels.

## GAMM

::: {#fig-gamm-gcv layout-ncol=2}

![Closest in time.](Figures/Models/last_GCV.Cp_diagnostic_custom.png)

![Nearest.](Figures/Models/last_GCV.Cp_diagnostic_custom.png)

![Highest score.](Figures/Models/last_GCV.Cp_diagnostic_custom.png)

Adjusted predictions for the FCM level on the three datasets. Here the GAMM is fitted using the GCV method.
:::

![Random intercept estimates on the three datasets using REML and GCV.](Figures/Models/partial_effect_feature_5.png){#fig-ri}

## Additional diagnostic plots

## Deviance explained by random intercept
