---
title: "Hunting Effect on Individual Deer Stress Level"
subtitle: "P15.2 Fortgeschrittenes Praxisprojekt"
author: "Nikolai German, Thomas Witzani, Ziqi Xu, Zhengchen Yuan, Baisu Zhou"
lang: en
format:
  pdf:
    documentclass: scrreprt
    number-sections: true
    crossref:
      chapters: true
    bibliography: references.bib
    classoption: [twocolumn, open=any]
    lof: false
    lot: false
    header-includes: |
      \counterwithout{figure}{chapter}
      \counterwithout{table}{chapter}
      \makeatletter
      \renewcommand\chapter{\@startsection{chapter}{0}{\z@}%
        {-3.5ex \@plus -1ex \@minus -.2ex}%
        {2.3ex \@plus.2ex}%
        {\normalfont\Large\bfseries}}
      \makeatother
      text: |
        \usepackage[font={small, rm}]{caption}
    toc: true
    geometry:
      - top=20mm
      - left=15mm
      - right=15mm
      - bottom=20mm
      - heightrounded
    mainfont: Arial
    colorlinks: true
---

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Hunting activity has an impact on animal populations through removal of individuals. Moreover, it may have a non-lethal effect of inducing stress. In this project, we analyze the short-term stress response of red deer in the Bavarian Forest National Park to hunting events. The stress level of a deer was measured by the concentration of *faecal cortisl metabolites (FCMs)* in faecal samples. Combining spatiotemporal information about the faecal samples, the deer which produced them, and the hunting events occurred in the time period of sample collection, we aim to address how the FCM level in a deer's faecal matter is associated with the temporal and spatial distance to a hunting event that could have affected the deer.

# Introduction

## Background

Apart from the change in populations size, the effects of hunting on wildlife have so far been studied mainly on the basis of behavioral changes. This project aims to investigate the physiological stress response in red deer using a non-invasive method, the measurement of FCMs.

## Data Generating Process

The data for the project origins in the *Bavarian Forest National Park*. Its location is highlighted in green in @fig-park_location. Within and on the borders of this area, red deer roam freely. Some of these deer have been collared with a GPS-device, which helps to track the movement. At some time, a *hunting event* happens and the deer experiences some amount of stress. Later, the deer defecates ("*defecation event*"). Subsequently, researchers visit the defecation location and collect a *faecal sample*.

![Location of Bavarian Forest National Park](Figures/sp_park_location.png){#fig-park_location}

Stress is expected to be higher in proximity[^1] to hunting events. With higher stress, FCM values are expected to be higher. @Huber2003 showed (@fig-fcm) that the FCM levels peak between 16 and 19 hours after a stress event (called "challenge"). Additionally we expect, that FCM levels are lower, the more time passes between defecation and sampling.

[^1]: this includes temporal and spatial proximity

![FCM levels over time](Figures/Huber_et_al_FCM_levels.png){#fig-fcm}

## Research Question

Therefore our research question is two-fold:

-   assess the effect of temporal and spatial distance on FCM level
-   assess if the time between defecation event and sample collection affect the FCM levels

# Data Analysis

We were provided with four distinct datasets.  In the following subchapters we are going to describe the main features of each data set and address any anomalies.

## Hunting Events

The dataset contains the location and time of 697 individual hunting events, spanning from 2020 to 2022. There are three main challenges:

i)  Just 519 of these 697 events have a complete timestamp, consisting of date and time of day. The remainder of 178 events only reported the date of the event.
ii) The events are not represented as a period of time, but as a as a single moment in time. Additionally, as shown in @fig-hunts_dates, there appears to be seasonality in the occurrence of hunts.
iii) Similiarly to ii), the events are only associated with a single spatial point. The locations of the events with complete timestamps are illustrated in @fig-hunt_locations.

![Hunts - Daily Count](Figures/hunts_dates.png){#fig-hunts_dates}

![Hunts - Locations](Figures/sp_hunts.png){#fig-hunt_locations}

## Movement Data

There are 40 collared deers which movements have been tracked completely or partially between February 2020 and February 2023. Some collars stopped working before the end-date, some deers got collared within the timespan of interest. The location of each individual deer is tracked on an hourly basis. The movement of four randomly selected deer is visualised in @fig-deers_locations. During the winter months, the deers roam in one of four enclosures within the national park.

![Deers - Locations of four Deer](Figures/sp_movement_4.png){#fig-deers_locations}

## Faecal Sample Data

The faecal sample dataset contains information on 809 faecal samples. Most importantly, the FCM level (in nanograms per gram \[ng/g\]), the location of the sample, as shown in @fig-samples_locations, the associated collared deer, the approximate time of defecation and the time of sampling. The samples were taken at irregular intervals, but with obvious seasonality (see @fig-samples_daily_count) from 2020 to 2022.

![Samples - Daily Count](Figures/samples_daily_count.png){#fig-samples_daily_count}

![Samples - Locations](Figures/sp_samples.png){#fig-samples_locations}

## Reproduction Data
The reproduction data contains reproduction information on some of the deers.
It has not been used in our analysis and modelling approach, for the reasons see @sec-feature_selection.

# Data Preprocessing

The datasets undergo preprocessing steps to facilitate analysis and modelling:

-   Convertion of Timestamps and Coordinates to a uniform format
-   Removal of entries with missing values (especially timestamps), zeros, or highly implausible data

Each FCM sample gets associated with all hunting events occurring before the sample was produced. The resulting dataset containes samples linked to all prior hunting events, creating multiple pairings per sample.

## Filtering {#sec-filtering}

A hunting event and a deer are separated by both space and time. Therefore we define the essential covariates to be:

i)  *Time Difference* between the hunting event and the subsequent defecation
ii) *Spatial Distance* between a deer and the hunting event at the exact time of the event

Additionally we identify other covariates:

iii) Time Difference between defecation and sampling (*Sample Delay*)
iv) Day of year \[1-365\][^1] (*Defecation Day*)
v)  Number of hunts a deer experiences before defecation (*Number of Other Hunts*)

[^1]: Not all values between 1 and 365 were observed. As shown in @fig-samples_daily_count, faecal samples were not collected during winter.

While each faecal sample can be associated with one or more hunting events prior to defecation, we do not use all possible pairings for our analysis. Suppose two hunting events occured before a deer defecated. The first hunting event occurred, say, 3 days prior to defecation, and the second event occurred 20 hours prior to defecation. According to @Huber2003, the FCM level increases as stress response, but this increase is short-term (see also @fig-fcm). If we did observe an increase of FCM level, this increase should predominantly be associated with the second hunting event. However, this assumption is only reasonable, if both hunting events had a small distance to the deer, as we expect far way hunting events to have little influence. With both temporal and spatial distance in mind, we focus on the *most relevant hunting event* for each faecal sample and propose the following definitions for this notion:

1.  *Closest in time*: Choosing the hunting event, which happened closest to 19 hours prior to the defecation event.
  This takes the findings of @Huber2003 into account, that cortisol metabolite concentrations peak around 19 hours post-stress event (see @fig-fcm).

1.  *Nearest*: Choosing the observation with the shortest spatial distance between the hunting event and the deer’s interpolated position at the time of the hunting event.

2.  *Highest score*: Introducing a scoring function to consider both spatial and temporal distance. We designed a score proportional to the inverse square of the distance and a "spike" function based on Time Difference (see @fig-score). The inverse square component is inspired by the inverse square law for sound intensity, spike function was inspired by the general dynamics of stress responses, incorporating insights from @Huber2003, and @Pinero2025. The observation with the highest score was selected. The scoring function is precisely given by
\begin{equation*}
  S(d, t) \propto \frac{1}{d^2} \cdot \begin{cases}
  f_\textbf{t}(t), \hspace{.1cm} \textbf{t} \sim \mathcal{N}(\mu, \sigma^2) &t \leq \mu \\
  f_\textbf{t}(t), \hspace{.1cm} \textbf{t} \sim \mathcal{Laplace}(\mu, b) &t > \mu,
  \end{cases}
\end{equation*}
where $d$ is the spatial distance, $t$ the Time Difference between hunting and defecation event, while $\mu = 19$, once again incoporates @Huber2003 findings. $\sigma = 2$ and $b = 2.5$ are shape paramters.

![Score Function](Figures/Timediff_Function_impact_curve.png){#fig-score}

Having identified the most relevant hunting event, covariate i) can be calculated easily as the time difference between the hunting event and the defecation event. To obtain covariate ii) we have to take in account, that the movement data is recorded in 1-hour intervals, while the hunting events occur at arbitrary time points. Therefore we need to approximate the exact deer positions at hunting event times. We interpolate deer positions at the timestamp of each hunting event, assuming constant velocity and linear movement. Suppose a hunting event occurred at time $t$, but we only know the deer's location at time $t_0, t_1$ with $t_0 < t < t_1$. Then we approximate the location $r(t)$ of the deer at time $t$ by
\begin{equation*}
  r(t) \approx r(t_0) + \frac{t - t_0}{t_1 - t_0} (r(t_1) - r(t_0)),
\end{equation*}
where $r(t_0)$ and $r(t_1)$ denote the recorded locations of the deer at time $t_0$ and $t_1$, respectively. We define covariate ii) to be the distance between the approximated deer location and the location of the hunting event. In cases where the time point of a movement recording coincides with that of a hunting event, we use the exact distance.

Covariates iii) and iv) are again easy to obtain. For covariate v), we need to define a cutoff point in time and space, to identify which other hunting events could have affected a deer as well (see @tbl-thresholds).

```{r include=TRUE, echo=FALSE}
#| label: tbl-thresholds
#| tbl-cap: "The three proposed DataSets. For each DataSet, *Temporal* refers to the upper limit of Time Difference between Hunting Event an Defecation Event, with the lower limit beeing zero. *Spatial* refers to the upper limit of the distance between deer and Hunting event, with the lower beeing zero as well."
data <- readRDS("Data/intermediate/param_grid.RDS")
data <- dplyr::select(data, filter_criterion, gut_retention_time_upper, distance_threshold)
tab <- knitr::kable(data, 
             format = "latex", 
             align = c("l", "r", "r"), 
             col.names = c("DataSet",
                          "Temporal [h]",
                          "Spatial [km]"
                          ))

kableExtra::kable_styling(tab, font_size = 10)
```

## Uncertainties

A major challenge in our analysis is the large uncertainty in data which propogates through the pre-processing steps into our models.

First, the uncertainty about spatial distances between deer and hunting events is large. While the movement of deer was tracked at hourly intervals, hunting events occurred irregularly. In our interpolation-based approximation of a deer's location at the time of hunting event, the approximation error is unknown.

Second, we have very limited information for addressing the short-term stress response of the deer. On the one hand, the available data contain only 500 hunting events with complete time and location information scattered across a 30km $\times$ 30km area in the span of two years. The observed hunting events only populate the space-time scarcely. On the other hand, we observe in @fig-deers_locations that the deer tended to roam around within a small area. As a result, each deer is likely to have only encountered very few hunting events at small spatial and temporal distances.

Third, there could be a large number of confounders for which we possess no information. Based on GPS coordinates, we can compute Euclidean distances between deer and hunting events. However, we cannot account for terrain and vegetation which could affect the propagation of sound and therefore contaminate the potential effect of hunting events. Furthermore, there could be unobserved stress stimuli, such as weather conditions, predators, and human activities other than hunting.

Fourth, we assumed that each hunting event was actually a sound event (i.e. a shot was fired). Therefore, we weighted the value of our score function by the inverse square distance.

# Model Selection

To address how the FCM level depends on Time Difference and spatial distance, we follow a statistical approach for interpretability and a machine learning approach for exploration. In this section, we present details on model specification. Both approaches use all the datasets shown in @tbl-datasets.

```{r include=TRUE, echo=FALSE}
#| label: tbl-datasets 
#| tbl-cap: "Count of individual deer and faecal sample for each of the proposed DataSets." 
data <- readRDS("Data/processed/Datasets.RDS")
data <- dplyr::select(data, filter_criterion, unique_deers, obs)
tab <- knitr::kable(data, 
                    format = "latex", 
                    align = c("r", "r", "r"),
                    col.names = c("DataSet",
                                  "Deer",
                                  "Observations"))
kableExtra::kable_styling(tab, font_size = 10)
```

## Statistical modeling approach {#sec-stat_model}

For each dataset shown in @tbl-datasets, we consider the five covariates introduced in @sec-filtering.

The *Time Difference* and *spatial distance* are of main interest for our first research question. The effect of *sample delay* is the subject of our second research question. We consider the *day of defecation* as a potential confounder, as the deer's stress level exhibits seasonal patterns [@Vilela2020]. The *number of other relevant hunting events* reflects the intensity of recent hunting activity. In time periods of frequent hunting events, a deer might have a generally higher stress level, or adaptation might occur which dampens the stress response towards new hunting events.

We propose a generalized additive mixed model (GAMM) to account for potentially non-linear effects of covariates and potential individual differences between the observed deer. We use the R package `mgcv` [@mgcv] to fit the models. The covariates Time Difference, Distance, Sample Delay, and Defecation Day are encoded by penalized cubic regression splines. We do not use a cyclical spline for Defecation Day, because faecal samples were not collected during winter and therefore Defecation Day is not a cyclical variable. The Number of Other Relevant Hunting Events is adopted as a linear effect. We further introduce a random intercept for each deer.

For the distributional assumption, we use the Gamma family with a log link. Since the FCM level is non-negative, we expect the Gamma assumption to more appropriate than Gaussian. A full specification of our GAMM model is as follows. Let $i = 1,\dots,N$ be the indices of the deer and $j = 1,\dots,n_i$ be the indices of faecal samples for each deer
\begin{align*}
  \textup{FCM}_{ij} &\overset{\mathrm{iid}}{\sim} \mathcal{Ga}\left( \nu, \frac{\nu}{\mu_{ij}} \right) \quad\text{for}\; j = 1,\dots,n_i, \\
  \mu_{ij} &= \mathbb{E}(\textup{FCM}_{ij}) = \exp(\eta_{ij}), \\
  \eta_{ij} &= \beta_0 \\
  &+ \beta_1 \textup{Number of Other Hunts}_{ij} \\
  &+ f_1(\textup{Time Difference}_{ij}) + f_2(\textup{Distance}_{ij}) \\
  &+ f_3(\textup{Sample Delay}_{ij}) + f_4(\textup{Defecation Day}_{ij}) \\
  &+ \gamma_{i}, \\
  \gamma_i &\overset{\mathrm{iid}}{\sim} \mathcal{N}(0, \sigma_\gamma^2),
\end{align*}
where $f_1, f_2, f_3, f_4$ are penalized cubic regression splines, $\sigma_\gamma^2 > 0$, and $\nu > 0$.

Our model has two major limitations. First, it does not account for potential interactions between the covariates. Second, the random intercept term can only capture different base stress levels, but not differences in stress response. However, given the limited data, one must trade off between model complexity and stability in estimation. In fact, our current model already exhibits instability with respect to estimation procedures, which we discuss in @sec-results.

## Machine learning approach

@Chen2016 introduced XGBoost as a machine learning algorithm that improves prediction accuracy by building an ensemble of decision trees sequentially. Each new tree corrects the errors made by previous trees. XGBoost minimizes a loss function using gradient boosting (hence the name) by iteratively adding trees that best reduce the residual errors. Simultaneously, complexity gets penalized through regularization to prevent overfitting. A major feature of XGBoost is that it doesn't require specifying a parametric relationship between target and explanatory variables.

We propose a xgboost model using the R package `xgboost` [@ChenXgboost], choosing *spatial distance* and *Time Difference* as covariates. To find the best fitting model for each dataset (see @tbl-datasets), we tune hyperparamters of the proposed xgboost model. We choose to tune the following paramters, using randomized grid search [@Bergstra2012]:

-   *maximum depth*:  Controls the maximum depth of each decision tree, determining how complex each tree can become.
-   $\eta$:  The learning rate, controls how much each new tree contributes to the ensemble, affecting how quickly or cautiously the model learns.
-   $\gamma$:  The minimum loss reduction required to make a split, acting as a regularization parameter that prevents creating splits that don't significantly improve the model.
-   *subsample*:  Specifies the fraction of training data used to build each tree, introducing randomness to prevent overfitting.
-   *features by tree*:  Determines the fraction of features (columns) randomly sampled for each tree, increasing diversity among trees.
-   *minimum weight of child*:  Minimum sum of instance weight needed in a child node, helping control the complexity of the model by preventing overly specific partitions.

# Model Evaluation {#sec-results}

## GAMMs

We fitted and evaluated GAMM models across the three datasets, using REML and GCV as parameter estimation methods. We observed high instability with respect to the choice of dataset and estimation method.

::: {#fig-gamm-reml layout-ncol=1}

![Closest in time](Figures/Models/last_REML_diagnostic_custom.png)

![Nearest](Figures/Models/nearest_REML_diagnostic_custom.png)

![Highest score](Figures/Models/score_REML_diagnostic_custom.png)

Adjusted predictions for the FCM level on the three datasets. The GAMM is fitted with the REML method. Each plot shows the predicted values of the FCM level in dependence of one covariate. The other covariants are held constant at the mean. The grey area shows the approximate confidence band (mean $\pm$ 1.96 standard error).
:::

In models estimated with the REML method, the smooth effects are penalized to almost linear, as shown in @fig-gamm-reml. While the fitted curves have a similar tendency across the datasets, the standard error in estimation is generally high. Given such high uncertainty, no interpretation of the estimates is reliable. The GCV method yields more wiggly smooth effect estimates, which are visualized in @fig-gamm-gcv, but high uncertainty persists. For the other covariates, we also observe high uncertainty and therefore avoid making any unreliable statement.

On the "highest score" dataset which contains more observations than the other two datasets, both estimation methods agree on a negative non-linear effect of Sample Delay. This is in accordance with our prior knowledge that the FCM level in the faecal sample decays after defecation [@Huber2003].

Similar to the smooth and linear effects, estimation of the deer-specific random intercepts exhibits high instability. In particular, the estimated random intercepts differ in order of magnitude across different dataset (see @fig-ri).

## XGBoost

The XGBoost model outperforms GAMM on the "highest score" and "nearest" dataset in terms of model fit measured by root mean squared error (RMSE), but performs worse on the "closest in time" dataset (see @tbl-rmse). After reviewing the hyperparameters (see @tbl-xgboost_hp) and comparisons between models trained on the actual data and the data with randomized labels we concluded that the XGBoost models likely did not learn noise and therefore are not overfitting.

```{r include=TRUE, echo=FALSE}
#| label: tbl-rmse 
#| tbl-cap: "Comparison of RMSE between GAMMs and XGBoost models. The RMSE score is computed on all observations in each dataset." 
data <- readRDS("Data/processed/ComparisonRMSE.RDS")
data$rmse <- round(data$rmse, 2)
tab <- knitr::kable(data, 
                    format = "latex", 
                    align = c("r", "r", "r"),
                    col.names = c("DataSet",
                                  "Model",
                                  "RMSE"))
kableExtra::kable_styling(tab, font_size = 10)
```

::: {#fig-xgboost_predictions layout-ncol=1}

![Closest in time](Figures/Models/xgboost_last.png)

![Nearest](Figures/Models/xgboost_nearest.png)

![Highest score](Figures/Models/xgboost_score.png)

Predictions of XGBoost models on the three datasets. The points are all observations within each dataset.
:::

We visualize the predictions of XGBoost models in @fig-xgboost_predictions. One would expect an increase in the FCM level closer to the zero point, however we did not observe this for models trained on the first two datasets. On the "highest score" dataset we observe a slight increase close to zero, but the same model also predicts a high plateau for time differences above 33 hours and spatial distances between 11.5 and 16 km. The XGBoost models show a relatively weak and very unclear effect.

# Conclusion & Outlook {#sec-outlook}

Due to the high level of uncertainty in the data, we were not able to show a consistent effect of spatial and temporal proximity to a hunting event on the FCM levels. However, we were able to show to a certain extent that the FCM level decreases with increasing sample delay.

We believe that a more rigorous approach to recording hunting events (e.g., tracking timespans rather than single moments and enforcing complete timestamps), coupled with a larger dataset and a more directed strategy (e.g., intentionally creating greater overlap of hunting events, movement data, and fecal samples in time and space), could reduce uncertainty and yield clearer results.

\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}

We would like to express our deepest gratitude to *Dr. Nicolas Ferry* for providing us with the opportunity to work on this project.

*Daniel Schlichting*'s mentorship throughout the project was invaluable. We thank him for his guidance and patience.

\chapter*{References}
\addcontentsline{toc}{chapter}{References}

::: {#refs}
:::

\onecolumn
# Appendix

## Reproduction data {#sec-feature_selection}

<!-- descriptive analysis ... -->

As the reproductive data only contain information on a subset of the deer, we were faced with the decision of how to label the rest of the deer ("pregnant"/"not pregnant"/NA). We are convinced that imputing this information would introduce a huge bias. For this reason, we deliberately chose not to include pregnancy data in our model. However, we are strongly in favour of including additional characteristics that could explain a shift in baseline stress levels.

## GAMM

::: {#fig-gamm-gcv layout-ncol=2}

![Closest in time](Figures/Models/last_GCV.Cp_diagnostic_custom.png)

![Nearest](Figures/Models/last_GCV.Cp_diagnostic_custom.png)

![Highest score](Figures/Models/last_GCV.Cp_diagnostic_custom.png)

Adjusted predictions for the FCM level on the three datasets. Here the GAMM is fitted using the GCV method.
:::

![Random intercept estimates on the three datasets using REML and GCV.](Figures/Models/partial_effect_feature_5.png){#fig-ri}

\newpage
## XGBoost

![3D Visualization of predictions for the FCM level on the three datasets by the XGBoost models. The observed data are shown as black points.](Figures/Models/combined_xgboost_plots.png)

```{r include=TRUE, echo=FALSE}
#| label: tbl-xgboost_hp 
#| tbl-cap: "Tuned hyperparameters for the XGBoost models."
data <- readRDS("Data/processed/XGBoostHyperparameters.RDS")
tab <- knitr::kable(data, 
                    format = "latex", 
                    align = rep("r", 7),
                    booktabs = TRUE,
                    col.names = c("DataSet",
                                  "Max. depth",
                                  "$\\eta$",
                                  "$\\gamma$",
                                  "Subsample",
                                  "Features by tree",
                                  "Min. weight of child"),
                    digits = 2,
                    escape = FALSE)
kableExtra::kable_styling(tab, font_size = 10)
```
